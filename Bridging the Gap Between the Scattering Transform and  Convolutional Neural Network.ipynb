{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kymatio/kymatio.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_IxFBKl7Vb7L",
        "outputId": "e12d4022-0e99-44b1-c321-5f654d546e5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kymatio'...\n",
            "remote: Enumerating objects: 6471, done.\u001b[K\n",
            "remote: Counting objects: 100% (259/259), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 6471 (delta 126), reused 178 (delta 91), pack-reused 6212 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6471/6471), 2.59 MiB | 29.50 MiB/s, done.\n",
            "Resolving deltas: 100% (4281/4281), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision kymatio numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MD5DYNWsVb-D",
        "outputId": "9f9ff94d-d284-44b4-c676-575397e7d299"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Collecting kymatio\n",
            "  Downloading kymatio-0.3.0-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Collecting appdirs (from kymatio)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting configparser (from kymatio)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kymatio) (24.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kymatio) (1.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading kymatio-0.3.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: appdirs, configparser, kymatio\n",
            "Successfully installed appdirs-1.4.4 configparser-7.1.0 kymatio-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from kymatio.torch import Scattering2D\n",
        "from kymatio.scattering2d.core.scattering2d import scattering2d\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "O0knOA_8VcAu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to track weight changes\n",
        "@torch.no_grad()\n",
        "def track_weight_changes(initial_params, current_params):\n",
        "    changes = 0\n",
        "    for init, curr in zip(initial_params, current_params):\n",
        "        changes += (init - curr).abs().mean().item()\n",
        "    return changes\n",
        "\n",
        "# Training function\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Testing function\n",
        "def test(model, test_loader, criterion, device):\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, accuracy\n"
      ],
      "metadata": {
        "id": "UZ1jPeoWVcDS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class 1: Fixed Scattering Classifier\n",
        "class FixedScatteringClassifier(nn.Module):\n",
        "    def __init__(self, J, shape, L, output_size=10):\n",
        "        super(FixedScatteringClassifier, self).__init__()\n",
        "        self.scattering = Scattering2D(J=J, shape=shape)\n",
        "\n",
        "        dummy_input = torch.randn(1, 1, *shape)\n",
        "        scattering_output = self.scattering(dummy_input)\n",
        "\n",
        "        self.linear_in_size = scattering_output.numel()\n",
        "        self.linear = nn.Linear(self.linear_in_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.scattering(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def main_step1():\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    J = 2\n",
        "    shape = (28, 28)\n",
        "    L = 8\n",
        "\n",
        "    # Initialize and train the Fixed Scattering Classifier\n",
        "    model_fixed = FixedScatteringClassifier(J, shape, L).to(device)\n",
        "    optimizer_fixed = optim.Adam(model_fixed.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"Training with fixed scattering transform...\")\n",
        "    for epoch in range(3):\n",
        "        train(model_fixed, train_loader, optimizer_fixed, criterion, device)\n",
        "        test_loss, accuracy = test(model_fixed, test_loader, criterion, device)\n",
        "        print(f'Epoch {epoch+1}: Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # Save the trained model for further steps\n",
        "    torch.save(model_fixed.state_dict(), 'fixed_classifier.pth')\n",
        "    print(\"Step 1 completed: Fixed classifier training finished and saved.\")\n",
        "\n",
        "main_step1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRw-YZ7mVcF4",
        "outputId": "04ed458a-de4b-42b8-9c21-72909f9ecd21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 100MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 18.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 86.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.05MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Training with fixed scattering transform...\n",
            "Epoch 1: Test loss: 0.0002, Accuracy: 96.85%\n",
            "Epoch 2: Test loss: 0.0001, Accuracy: 97.68%\n",
            "Epoch 3: Test loss: 0.0001, Accuracy: 98.01%\n",
            "Step 1 completed: Fixed classifier training finished and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainable Scattering Model"
      ],
      "metadata": {
        "id": "RE1dXEbFWLQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScatteringTorch2DTrainable(nn.Module):\n",
        "    def __init__(self, J, shape, L=8, output_size=10, pretrained_classifier=None):\n",
        "        super(ScatteringTorch2DTrainable, self).__init__()\n",
        "        self.scattering = Scattering2D(J=J, shape=shape)\n",
        "        self.J = J\n",
        "        self.L = L\n",
        "        self.pad = self.scattering.pad\n",
        "        self.unpad = self.scattering.unpad\n",
        "        self.backend = self.scattering.backend\n",
        "        self.max_order = self.scattering.max_order\n",
        "        self.out_type = self.scattering.out_type\n",
        "\n",
        "        self.phi = self.scattering.phi.copy()\n",
        "        self.psi = [p.copy() for p in self.scattering.psi]\n",
        "\n",
        "        # Convert phi and psi levels to trainable parameters\n",
        "        self.params = nn.ParameterList([nn.Parameter(torch.tensor(level).unsqueeze(-1), requires_grad=True)\n",
        "                                            for level in self.phi['levels']])\n",
        "        psi_params = nn.ParameterList([nn.Parameter(torch.tensor(psi_level).unsqueeze(-1), requires_grad=True)\n",
        "                                            for psi in self.psi\n",
        "                                            for psi_level in psi['levels']])\n",
        "\n",
        "        self.params.extend(psi_params)\n",
        "\n",
        "        # Load the pre-trained classifier and freeze its parameters\n",
        "        if pretrained_classifier is not None:\n",
        "            self.linear = pretrained_classifier.linear  # Use the pre-trained classifier's linear layer\n",
        "        else:\n",
        "            dummy_input = torch.randn(1, 1, *shape)\n",
        "            scattering_output = self.scattering(dummy_input)\n",
        "            scattering_output_size = scattering_output.numel()\n",
        "            self.linear = nn.Linear(scattering_output_size, output_size)\n",
        "\n",
        "        # Freeze the classifier parameters\n",
        "        for param in self.linear.parameters():\n",
        "            param.requires_grad = False  # Freeze the pre-trained classifier\n",
        "\n",
        "    def load_filters(self):\n",
        "        \"\"\" This function loads filters from the module's parameters \"\"\"\n",
        "        # each time scattering is run, one needs to make sure self.psi and self.phi point to\n",
        "        # the correct buffers\n",
        "        param_dict = dict(self.named_parameters())\n",
        "\n",
        "        n = 0\n",
        "\n",
        "        # Load phi levels\n",
        "        phis = {k: v for k, v in self.phi.items() if k != 'levels'}\n",
        "        phis['levels'] = []\n",
        "        for phi_level in self.phi['levels']:\n",
        "            phis['levels'].append(param_dict['params.' + str(n)])\n",
        "            n += 1\n",
        "\n",
        "        # Load psi levels\n",
        "        psis = [{} for _ in range(len(self.psi))]\n",
        "        for j in range(len(self.psi)):\n",
        "            psis[j] = {k: v for k, v in self.psi[j].items() if k != 'levels'}\n",
        "            psis[j]['levels'] = []\n",
        "            for psi_level in self.psi[j]['levels']:\n",
        "                psis[j]['levels'].append(\n",
        "                    param_dict['params.' + str(n)]\n",
        "                )\n",
        "                n += 1\n",
        "\n",
        "        return phis, psis\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze()\n",
        "        batch_shape = x.shape[:-2]\n",
        "        signal_shape = x.shape[-2:]\n",
        "\n",
        "        x = x.reshape((-1,) + signal_shape)\n",
        "        phis, psis = self.load_filters()\n",
        "        # Apply scattering transform using loaded filters\n",
        "        S = scattering2d(x, self.pad, self.unpad, self.backend, self.J, self.L,\n",
        "                         phis, psis, self.max_order, 'array')\n",
        "\n",
        "        # Pass through the frozen classifier\n",
        "        S = S.view(S.size(0), -1)  # Flatten the scattering output\n",
        "        output = self.linear(S)  # Classify using the frozen classifier\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "-UjS-v65VcIc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_step2():\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    J = 2\n",
        "    shape = (28, 28)\n",
        "    L = 8\n",
        "\n",
        "    # Load the Fixed Scattering Classifier\n",
        "    model_fixed = FixedScatteringClassifier(J=2, shape=(28,28), L=8)\n",
        "    model_fixed.load_state_dict(torch.load('fixed_classifier.pth'))\n",
        "    model_fixed.eval()\n",
        "\n",
        "    # Initialize and train the Scattering Classifier\n",
        "    model_1 = ScatteringTorch2DTrainable(J=2, shape = (28,28), L=8, pretrained_classifier=model_fixed).to(device)\n",
        "\n",
        "    first_model = ScatteringTorch2DTrainable(J=2, shape = (28,28), L=8, pretrained_classifier=model_fixed).to(device)\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(filter(lambda x: x.requires_grad, model_1.parameters()), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    changes = []\n",
        "\n",
        "\n",
        "    print(\"Training scattering transform...\")\n",
        "    for epoch in range(3):\n",
        "        train(model_1, train_loader, optimizer, criterion, device)\n",
        "        test_loss, accuracy = test(model_1, test_loader, criterion, device)\n",
        "        change = track_weight_changes(first_model.parameters(), model_1.parameters())\n",
        "        print(f'Epoch {epoch+1}: Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, Change: {change:.2f}')\n",
        "        changes.append(change)\n",
        "\n",
        "    # Save the trained model for further steps\n",
        "    torch.save(model_1.state_dict(), 'trainable_wavelets_classifier.pth')\n",
        "    print(\"Step 2 completed: Trainable wavelets classifier training finished and saved.\")\n",
        "\n",
        "main_step2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmhCtFd9V-WN",
        "outputId": "9069db05-ca68-49a5-fc83-8a1176b8eff1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ffb58e62eebc>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_fixed.load_state_dict(torch.load('fixed_classifier.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training scattering transform...\n",
            "Epoch 1: Test loss: 0.0000, Accuracy: 98.48%, Change: 0.60\n",
            "Epoch 2: Test loss: 0.0000, Accuracy: 98.64%, Change: 1.00\n",
            "Epoch 3: Test loss: 0.0000, Accuracy: 98.71%, Change: 1.40\n",
            "Step 2 completed: Trainable wavelets classifier training finished and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainable Random Scattering Model"
      ],
      "metadata": {
        "id": "Qt3aa6NgWY4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomScatteringTorch2DTrainable(nn.Module):\n",
        "    def __init__(self, J, shape, L=8, output_size=10, pretrained_classifier=None):\n",
        "        super(RandomScatteringTorch2DTrainable, self).__init__()\n",
        "        self.scattering = Scattering2D(J=J, shape=shape)\n",
        "        self.J = J\n",
        "        self.L = L\n",
        "        self.pad = self.scattering.pad\n",
        "        self.unpad = self.scattering.unpad\n",
        "        self.backend = self.scattering.backend\n",
        "        self.max_order = self.scattering.max_order\n",
        "        self.out_type = self.scattering.out_type\n",
        "\n",
        "        self.phi = self.scattering.phi.copy()\n",
        "        self.psi = [p.copy() for p in self.scattering.psi]\n",
        "\n",
        "        # Convert phi and psi levels to trainable parameters\n",
        "        self.params = nn.ParameterList([\n",
        "            nn.Parameter(torch.randn(*level.shape).unsqueeze(-1), requires_grad=True)\n",
        "                                            for level in self.phi['levels']\n",
        "        ])\n",
        "        psi_params = nn.ParameterList([nn.Parameter(torch.randn(*psi_level.shape).unsqueeze(-1), requires_grad=True)\n",
        "                                            for psi in self.psi\n",
        "                                            for psi_level in psi['levels']])\n",
        "\n",
        "        self.params.extend(psi_params)\n",
        "\n",
        "        # Load the pre-trained classifier and freeze its parameters\n",
        "        if pretrained_classifier is not None:\n",
        "            self.linear = pretrained_classifier.linear  # Use the pre-trained classifier's linear layer\n",
        "        else:\n",
        "            dummy_input = torch.randn(1, 1, *shape)\n",
        "            scattering_output = self.scattering(dummy_input)\n",
        "            scattering_output_size = scattering_output.numel()\n",
        "            self.linear = nn.Linear(scattering_output_size, output_size)\n",
        "\n",
        "        # Freeze the classifier parameters\n",
        "        for param in self.linear.parameters():\n",
        "            param.requires_grad = False  # Freeze the pre-trained classifier\n",
        "\n",
        "    def load_filters(self):\n",
        "        \"\"\" This function loads filters from the module's parameters \"\"\"\n",
        "        # each time scattering is run, one needs to make sure self.psi and self.phi point to\n",
        "        # the correct buffers\n",
        "        param_dict = dict(self.named_parameters())\n",
        "\n",
        "        n = 0\n",
        "\n",
        "        # Load phi levels\n",
        "        phis = {k: v for k, v in self.phi.items() if k != 'levels'}\n",
        "        phis['levels'] = []\n",
        "        for phi_level in self.phi['levels']:\n",
        "            phis['levels'].append(param_dict['params.' + str(n)])\n",
        "            n += 1\n",
        "\n",
        "        # Load psi levels\n",
        "        psis = [{} for _ in range(len(self.psi))]\n",
        "        for j in range(len(self.psi)):\n",
        "            psis[j] = {k: v for k, v in self.psi[j].items() if k != 'levels'}\n",
        "            psis[j]['levels'] = []\n",
        "            for psi_level in self.psi[j]['levels']:\n",
        "                psis[j]['levels'].append(\n",
        "                    param_dict['params.' + str(n)]\n",
        "                )\n",
        "                n += 1\n",
        "\n",
        "        return phis, psis\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze()\n",
        "        batch_shape = x.shape[:-2]\n",
        "        signal_shape = x.shape[-2:]\n",
        "\n",
        "        x = x.reshape((-1,) + signal_shape)\n",
        "        phis, psis = self.load_filters()\n",
        "        # Apply scattering transform using loaded filters\n",
        "        S = scattering2d(x, self.pad, self.unpad, self.backend, self.J, self.L,\n",
        "                         phis, psis, self.max_order, 'array')\n",
        "\n",
        "        # Pass through the frozen classifier\n",
        "        S = S.view(S.size(0), -1)  # Flatten the scattering output\n",
        "        output = self.linear(S)  # Classify using the frozen classifier\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "Z8KQ073OV-f6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_step3():\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    J = 2\n",
        "    shape = (28, 28)\n",
        "    L = 8\n",
        "\n",
        "    # Load the Fixed Scattering Classifier\n",
        "    model_fixed = FixedScatteringClassifier(J=2, shape=(28,28), L=8)\n",
        "    model_fixed.load_state_dict(torch.load('fixed_classifier.pth'))\n",
        "    model_fixed.eval()\n",
        "\n",
        "    model_filters_train = ScatteringTorch2DTrainable(J=2, shape=(28,28), L=8)\n",
        "    model_filters_train.load_state_dict(torch.load('trainable_wavelets_classifier.pth'))\n",
        "    model_filters_train.eval()\n",
        "\n",
        "    # Initialize and train the Randm Scattering Classifier\n",
        "    model_1 = RandomScatteringTorch2DTrainable(J=2, shape = (28,28), L=8, pretrained_classifier=model_fixed).to(device)\n",
        "\n",
        "    first_model = RandomScatteringTorch2DTrainable(J=2, shape = (28,28), L=8, pretrained_classifier=model_fixed).to(device)\n",
        "\n",
        "    second_model = RandomScatteringTorch2DTrainable(J=2, shape = (28,28), L=8, pretrained_classifier=model_filters_train).to(device)\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(filter(lambda x: x.requires_grad, model_1.parameters()), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    changes = []\n",
        "    changes2 = []\n",
        "\n",
        "\n",
        "    print(\"Training random scattering transform...\")\n",
        "    for epoch in range(3):\n",
        "        train(model_1, train_loader, optimizer, criterion, device)\n",
        "        test_loss, accuracy = test(model_1, test_loader, criterion, device)\n",
        "        change = track_weight_changes(first_model.parameters(), model_1.parameters())\n",
        "        change2 = track_weight_changes(second_model.parameters(), model_1.parameters())\n",
        "        print(f'Epoch {epoch+1}: Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, Change: {change:.2f}')\n",
        "        print(f'Epoch {epoch+1}: Test loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%, Change: {change2:.2f}')\n",
        "        changes.append(change)\n",
        "        changes2.append(change2)\n",
        "\n",
        "    # Save the trained model for further steps\n",
        "    torch.save(model_1.state_dict(), 'random_wavelets_classifier.pth')\n",
        "    print(\"Step 3 completed: random wavelets classifier training finished and saved.\")\n",
        "\n",
        "main_step3()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOnRSxZ-VcLC",
        "outputId": "c4cc6747-6d33-44db-9b8d-f9f0b61db914"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-31571162befa>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_fixed.load_state_dict(torch.load('fixed_classifier.pth'))\n",
            "<ipython-input-26-31571162befa>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_filters_train.load_state_dict(torch.load('trainable_wavelets_classifier.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training random scattering transform...\n",
            "Epoch 1: Test loss: 0.0006, Accuracy: 82.19%, Change: 20.20\n",
            "Epoch 1: Test loss: 0.0006, Accuracy: 82.19%, Change: 19.79\n",
            "Epoch 2: Test loss: 0.0003, Accuracy: 91.20%, Change: 20.13\n",
            "Epoch 2: Test loss: 0.0003, Accuracy: 91.20%, Change: 19.73\n",
            "Epoch 3: Test loss: 0.0002, Accuracy: 93.97%, Change: 20.08\n",
            "Epoch 3: Test loss: 0.0002, Accuracy: 93.97%, Change: 19.70\n",
            "Step 3 completed: random wavelets classifier training finished and saved.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}